{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import cv2 \n",
    "import random\n",
    "from scipy.linalg import sqrtm\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "import collections\n",
    "import PIL\n",
    "import tqdm\n",
    "\n",
    "from LLR_classifier import *\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "batch_size = 100\n",
    "z_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "    \n",
    "def kaiming_init(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        init.kaiming_normal(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "        m.weight.data.fill_(1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim=10, nc=3):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.nc = nc\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            View((-1, 1024*4*4)),\n",
    "            nn.Linear(1024*4*4, z_dim)\n",
    "        )\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim=10, nc=3):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.nc = nc\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1024*8*8),\n",
    "            View((-1, 1024, 8, 8)),\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, nc, 1)\n",
    "        )\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.z_dim, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, x):\n",
    "        dis = self.main(x)\n",
    "        return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfandw/anaconda3/envs/env/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder(z_dim=128, nc=3).to(device)\n",
    "dec = Decoder(z_dim=128, nc=3).to(device)\n",
    "dis = Discriminator(z_dim=128).to(device)\n",
    "\n",
    "enc.load_state_dict(torch.load('saved_model_x1/encoder.pth'))\n",
    "dec.load_state_dict(torch.load('saved_model_x1/decoder_.pth'))\n",
    "dis.load_state_dict(torch.load('saved_model_x1/discriminator_.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train image directory\n",
    "train_path = '/home/irfandw/Works/dataset/data_aligned_resize/copy1/Training/Subjects/'\n",
    "\n",
    "#Test image directory\n",
    "test_path = '/home/irfandw/Works/dataset/data_aligned_resize/FRGC/Testing/Subjects/'\n",
    "\n",
    "\n",
    "#Pair train of FRGC directory\n",
    "pairs_path1 = 'pairs_new/train/shufflepairs_genuine.txt'\n",
    "pairs_path2 = 'pairs_new/train/shufflepairs_train_impostor_new.txt'\n",
    "\n",
    "#Pair test of FRGC directory\n",
    "pairs_test1 = 'pairs_frgc/shufflepairs_FRGC_test_genuine.txt'\n",
    "pairs_test2 = 'pairs_frgc/shufflepairs_FRGC_test_impostor.txt'\n",
    "pairs_path3 = 'pairs_frgc/pairs_frgc.txt'\n",
    "\n",
    "\n",
    "file_ext = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pairs(pairs_filename, lfw_flag=True):\n",
    "    pairs = []\n",
    "    with open(pairs_filename, 'r') as f:\n",
    "        if lfw_flag:\n",
    "            for line in f.readlines()[1:]:\n",
    "                pair = line.strip().split()\n",
    "                pairs.append(pair)\n",
    "        else:\n",
    "            for line in f.readlines():\n",
    "                pair = line.strip().split()\n",
    "                pairs.append(pair)      \n",
    "    return np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training pairs\n",
    "pairs1 = read_pairs(pairs_path1, lfw_flag=False)\n",
    "pairs2 = read_pairs(pairs_path2, lfw_flag=False)\n",
    "\n",
    "#Load testing pairs\n",
    "pairtest1 = read_pairs(pairs_test1, lfw_flag=False)\n",
    "pairtest2 = read_pairs(pairs_test2, lfw_flag=False)\n",
    "pairsx = read_pairs(pairs_path3, lfw_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of path for training and testing pairs\n",
    "def get_paths(directory, pairs, file_ext):\n",
    "    nrof_skipped_pairs = 0\n",
    "    path_list = []\n",
    "    issame_list = []\n",
    "    for pair in pairs:\n",
    "        if len(pair) == 3:\n",
    "            path0 = os.path.join(directory, pair[0], pair[1])\n",
    "            path1 = os.path.join(directory, pair[0], pair[2])\n",
    "            issame = True\n",
    "        elif len(pair) == 4:\n",
    "            path0 = os.path.join(directory, pair[0], pair[1])\n",
    "            path1 = os.path.join(directory, pair[2], pair[3])\n",
    "            issame = False\n",
    "        if os.path.exists(path0) and os.path.exists(path1):    # Only add the pair if both paths exist\n",
    "            path_list += (path0,path1)\n",
    "            issame_list.append(issame)\n",
    "        else:\n",
    "            nrof_skipped_pairs += 1\n",
    "    if nrof_skipped_pairs>0:\n",
    "        print('Skipped %d image pairs' % nrof_skipped_pairs)\n",
    "    \n",
    "    return path_list, issame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training and testing\n",
    "path_list1, issame_list1 = get_paths(train_path, pairs1, file_ext)\n",
    "path_list2, issame_list2 = get_paths(train_path, pairs2, file_ext)\n",
    "\n",
    "path_list_test1, issame_list_test1 = get_paths(test_path, pairtest1, file_ext)\n",
    "path_list_test2, issame_list_test2 = get_paths(test_path, pairtest2, file_ext)\n",
    "path_list3, issame_list3 = get_paths(test_path, pairsx, file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ground truth\n",
    "gt = np.asarray(issame_list3)\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, path_list, issame_list, transforms, split = 'test'):\n",
    "        \n",
    "        self.files = collections.defaultdict(list)\n",
    "        self.split = split\n",
    "        self.files[split] =  path_list\n",
    "        self.pair_label = issame_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files[self.split])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_file = self.files[self.split][index]\n",
    "        img = PIL.Image.open(img_file)\n",
    "        if DEBUG:\n",
    "            print (img_file)\n",
    "        im_out = self.transforms(img)\n",
    "        return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training dataset\n",
    "train_loader_gen = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list1, issame_list1, test_transform), \n",
    "                        batch_size=1, shuffle=False )\n",
    "\n",
    "train_loader_im = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list2, issame_list2, test_transform), \n",
    "                        batch_size=1, shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load testing dataset\n",
    "test_loader_gen = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list_test1, issame_list_test1, test_transform), \n",
    "                        batch_size=1, shuffle=False )\n",
    "\n",
    "test_loader_im = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list_test2, issame_list_test2, test_transform), \n",
    "                        batch_size=1, shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (main): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=65536, bias=True)\n",
       "    (1): View()\n",
       "    (2): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace)\n",
       "    (8): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace)\n",
       "    (11): ConvTranspose2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.eval()\n",
    "dec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Z_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images = []\n",
    "zgen_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(train_loader_gen):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = enc(data)\n",
    "        decod = dec(z_encoded)\n",
    "\n",
    "        recons_images.append(decod[0].cpu().numpy())\n",
    "        zgen_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_train = np.array(recons_images)\n",
    "zgen_ = np.array(zgen_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 2400)\n"
     ]
    }
   ],
   "source": [
    "z_reshape1 = zgen_.reshape((-1,256))\n",
    "z_reshape_rot1 = np.transpose(z_reshape1)\n",
    "add_ones = np.ones((1,2400))\n",
    "z_mat = np.concatenate((z_reshape_rot1, add_ones))\n",
    "print(z_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z_nonmated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_train = []\n",
    "zim_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(train_loader_im):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = enc(data)\n",
    "        decod = dec(z_encoded)\n",
    "\n",
    "        recons_images_impostor_train.append(decod[0].cpu().numpy())\n",
    "        zim_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_train = np.array(recons_images_impostor_train)\n",
    "zim_ = np.array(zim_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_reshape2 = zim_.reshape((-1,256))\n",
    "z_reshape_rot2 = np.transpose(z_reshape2)\n",
    "add_zeros = np.zeros((1,2400))\n",
    "z_nonmat = np.concatenate((z_reshape_rot2, add_zeros))\n",
    "print(z_nonmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate((z_mat, z_nonmat),axis=1)  #training data\n",
    "\n",
    "scipy.io.savemat('result_FRGC/train_new_ae.mat', mdict={\"X_tr\": train})\n",
    "\n",
    "train_with_binary = np.save('result_FRGC/train_bin_ae.npy', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing genuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_test = []\n",
    "zgen_test_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader_gen):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = enc(data)\n",
    "        decod = dec(z_encoded)\n",
    "\n",
    "        recons_images_genuine_test.append(decod[0].cpu().numpy())\n",
    "        zgen_test_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_test = np.array(recons_images_genuine_test)\n",
    "zgen_test_ = np.array(zgen_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_reshape2_test = zgen_test_.reshape((-1,256))\n",
    "z_reshape_rot2_test = np.transpose(z_reshape2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_test = []\n",
    "zim_test_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader_im):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = enc(data)\n",
    "        decod = dec(z_encoded)\n",
    "\n",
    "        recons_images_impostor_test.append(decod[0].cpu().numpy())\n",
    "        zim_test_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_test = np.array(recons_images_impostor_test)\n",
    "zim_test_ = np.array(zim_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_reshape2_test = zim_test_.reshape((-1,256))\n",
    "z_reshape_rot2_test = np.transpose(z_reshape2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "test_gen_pair = np.concatenate((z_reshape_rot1_test, z_reshape_rot2_test), axis=1)\n",
    "\n",
    "scipy.io.savemat('result_FRGC/test_gen_pair_ae.mat', mdict={\"X\": test_gen_pair})\n",
    "\n",
    "np.save('result_FRGC/test_gen_pair_ae.npy', test_gen_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('result_FRGC/train_bin_aae.npy')\n",
    "test = np.load('result_FRGC/test_gen_pair_aae.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8170366559975613\n",
      "(array([119]),)\n"
     ]
    }
   ],
   "source": [
    "#Finding the best Ndc value\n",
    "find = []\n",
    "\n",
    "for i in range(128):\n",
    "    M_global_hat, B_psinv, stdB_hat = train_LLR(train, Npc=128, Ndc=i)\n",
    "    LLR = LLR_computation(test, M_global_hat, B_psinv, stdB_hat)\n",
    "    \n",
    "    roc_auc = sklearn.metrics.roc_auc_score(gt, LLR[0])\n",
    "\n",
    "    find.append(roc_auc)\n",
    "\n",
    "find = np.array(find)\n",
    "print(np.max(find))\n",
    "print(np.where(find == np.max(find)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_global_hat, B_psinv, stdB_hat = train_LLR(train, Npc=128, Ndc=119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240,)\n"
     ]
    }
   ],
   "source": [
    "LLR = LLR_computation(test, M_global_hat, B_psinv, stdB_hat)\n",
    "#print(LLR)\n",
    "print(LLR[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8170\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = sklearn.metrics.roc_auc_score(gt, LLR[0])\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(gt, LLR[0])\n",
    "print ('ROC-AUC: %.04f' % roc_auc)\n",
    "# Plot and save ROC curve\n",
    "fig = plt.figure()\n",
    "plt.title('ROC - AAE z=128')\n",
    "plt.plot(fpr, tpr, lw=2, label='ROC (auc = %0.4f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
