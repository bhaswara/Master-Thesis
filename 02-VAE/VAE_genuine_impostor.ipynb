{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import cv2 \n",
    "import random\n",
    "from scipy.linalg import sqrtm\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "import collections\n",
    "import PIL\n",
    "import tqdm\n",
    "\n",
    "from LLR_classifier import *\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 100\n",
    "z_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_dim=10, nc=3):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.nc = nc\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(nc, 128, 4, 2, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, padding = 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 1024, 4, 2, padding = 1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            View((-1, 1024*4*4)),\n",
    "        )\n",
    "\n",
    "        self.mean = nn.Linear(1024*4*4, z_dim)\n",
    "        self.logvar = nn.Linear(1024*4*4, z_dim)\n",
    "\n",
    "\n",
    "    def reparametrize(self, mean, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        multi = torch.FloatTensor(std.size()).normal_().cuda()\n",
    "        multi = Variable(multi)\n",
    "        return multi.mul(std).add_(mean)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b_size = x.size(0)\n",
    "\n",
    "        h = self.encoder(x)\n",
    "        \n",
    "        mean, logvar = self.mean(h), self.logvar(h)\n",
    "\n",
    "        latent_z = self.reparametrize(mean, logvar)\n",
    "\n",
    "        return latent_z, mean, logvar\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim=10, nc = 3):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.nc = nc\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1024*8*8),\n",
    "            View((-1, 1024, 8, 8))\n",
    "        )\n",
    "        \n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, padding = 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, padding = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, padding = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, nc, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.decoder_lin(x)\n",
    "        out = self.decoder_conv(h)\n",
    "        return out\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    \"\"\"Encoder-Decoder architecture for both WAE-MMD and WAE-GAN.\"\"\"\n",
    "    def __init__(self, z_dim=128, nc=3):\n",
    "        super(VAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.nc = nc\n",
    "\n",
    "        self.encoder = Encoder(z_dim=z_dim, nc=nc)\n",
    "        self.decoder = Decoder(z_dim=z_dim, nc=nc)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent_z, mean, logvar = self.encoder(x)\n",
    "        rec_x = self.decoder(latent_z)\n",
    "        return rec_x, mean, logvar\n",
    "    \n",
    "    def _encode(self, x):\n",
    "        latent_z, _, _ = self.encoder(x)\n",
    "        return latent_z\n",
    "    \n",
    "    def _decode(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_net = VAE(z_dim=128, nc=3)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    VAE_net = VAE_net.cuda()\n",
    "\n",
    "VAE_net.load_state_dict(torch.load('saved_model_x0/vae.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train image directory\n",
    "train_path = '/home/irfandw/Works/dataset/data_aligned_resize/copy1/Training/Subjects/'\n",
    "\n",
    "#Test image directory\n",
    "test_path = '/home/irfandw/Works/dataset/data_aligned_resize/FRGC/Testing/Subjects/'\n",
    "\n",
    "\n",
    "#Pair train of FRGC directory\n",
    "pairs_path1 = 'pairs_new/train/shufflepairs_genuine.txt'\n",
    "pairs_path2 = 'pairs_new/train/shufflepairs_train_impostor_new.txt'\n",
    "\n",
    "#Pair test of FRGC directory\n",
    "pairs_test1 = 'pairs_frgc/shufflepairs_FRGC_test_genuine.txt'\n",
    "pairs_test2 = 'pairs_frgc/shufflepairs_FRGC_test_impostor.txt'\n",
    "pairs_path3 = 'pairs_frgc/pairs_frgc.txt'\n",
    "\n",
    "\n",
    "file_ext = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pairs(pairs_filename, lfw_flag=True):\n",
    "    pairs = []\n",
    "    with open(pairs_filename, 'r') as f:\n",
    "        if lfw_flag:\n",
    "            for line in f.readlines()[1:]:\n",
    "                pair = line.strip().split()\n",
    "                pairs.append(pair)\n",
    "        else:\n",
    "            for line in f.readlines():\n",
    "                pair = line.strip().split()\n",
    "                pairs.append(pair)      \n",
    "    return np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training pairs\n",
    "pairs1 = read_pairs(pairs_path1, lfw_flag=False)\n",
    "pairs2 = read_pairs(pairs_path2, lfw_flag=False)\n",
    "\n",
    "#Load testing pairs\n",
    "pairtest1 = read_pairs(pairs_test1, lfw_flag=False)\n",
    "pairtest2 = read_pairs(pairs_test2, lfw_flag=False)\n",
    "pairsx = read_pairs(pairs_path3, lfw_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of path for training and testing pairs\n",
    "def get_paths(directory, pairs, file_ext):\n",
    "    nrof_skipped_pairs = 0\n",
    "    path_list = []\n",
    "    issame_list = []\n",
    "    for pair in pairs:\n",
    "        if len(pair) == 3:\n",
    "            path0 = os.path.join(directory, pair[0], pair[1])\n",
    "            path1 = os.path.join(directory, pair[0], pair[2])\n",
    "            issame = True\n",
    "        elif len(pair) == 4:\n",
    "            path0 = os.path.join(directory, pair[0], pair[1])\n",
    "            path1 = os.path.join(directory, pair[2], pair[3])\n",
    "            issame = False\n",
    "        if os.path.exists(path0) and os.path.exists(path1):    # Only add the pair if both paths exist\n",
    "            path_list += (path0,path1)\n",
    "            issame_list.append(issame)\n",
    "        else:\n",
    "            nrof_skipped_pairs += 1\n",
    "    if nrof_skipped_pairs>0:\n",
    "        print('Skipped %d image pairs' % nrof_skipped_pairs)\n",
    "    \n",
    "    return path_list, issame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training and testing\n",
    "path_list1, issame_list1 = get_paths(train_path, pairs1, file_ext)\n",
    "path_list2, issame_list2 = get_paths(train_path, pairs2, file_ext)\n",
    "\n",
    "path_list_test1, issame_list_test1 = get_paths(test_path, pairtest1, file_ext)\n",
    "path_list_test2, issame_list_test2 = get_paths(test_path, pairtest2, file_ext)\n",
    "path_list3, issame_list3 = get_paths(test_path, pairsx, file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ground truth\n",
    "gt = np.asarray(issame_list3)\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, path_list, issame_list, transforms, split = 'test'):\n",
    "        \n",
    "        self.files = collections.defaultdict(list)\n",
    "        self.split = split\n",
    "        self.files[split] =  path_list\n",
    "        self.pair_label = issame_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files[self.split])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_file = self.files[self.split][index]\n",
    "        img = PIL.Image.open(img_file)\n",
    "        if DEBUG:\n",
    "            print (img_file)\n",
    "        im_out = self.transforms(img)\n",
    "        return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training dataset\n",
    "train_loader_gen = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list1, issame_list1, test_transform), \n",
    "                        batch_size=1, shuffle=False )\n",
    "\n",
    "train_loader_im = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list2, issame_list2, test_transform), \n",
    "                        batch_size=1, shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load testing dataset\n",
    "test_loader_gen = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list_test1, issame_list_test1, test_transform), \n",
    "                        batch_size=1, shuffle=False )\n",
    "\n",
    "test_loader_im = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list_test2, issame_list_test2, test_transform), \n",
    "                        batch_size=1, shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace)\n",
       "      (9): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): ReLU(inplace)\n",
       "      (12): View()\n",
       "    )\n",
       "    (mean): Linear(in_features=16384, out_features=128, bias=True)\n",
       "    (logvar): Linear(in_features=16384, out_features=128, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder_lin): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=65536, bias=True)\n",
       "      (1): View()\n",
       "    )\n",
       "    (decoder_conv): Sequential(\n",
       "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace)\n",
       "      (9): ConvTranspose2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAE_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Z_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images = []\n",
    "zgen_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(train_loader_gen):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = VAE_net._encode(data)\n",
    "        decod = VAE_net._decode(z_encoded)\n",
    "\n",
    "        recons_images.append(decod[0].cpu().numpy())\n",
    "        zgen_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_train = np.array(recons_images)\n",
    "zgen_ = np.array(zgen_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 2400)\n"
     ]
    }
   ],
   "source": [
    "z_reshape1 = zgen_.reshape((-1,256))\n",
    "z_reshape_rot1 = np.transpose(z_reshape1)\n",
    "add_ones = np.ones((1,2400))\n",
    "z_mat = np.concatenate((z_reshape_rot1, add_ones))\n",
    "print(z_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z_nonmated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_train = []\n",
    "zim_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(train_loader_im):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = VAE_net._encode(data)\n",
    "        decod = VAE_net._decode(z_encoded)\n",
    "\n",
    "        recons_images_impostor_train.append(decod[0].cpu().numpy())\n",
    "        zim_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_train = np.array(recons_images_impostor_train)\n",
    "zim_ = np.array(zim_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 2400)\n"
     ]
    }
   ],
   "source": [
    "z_reshape2 = zim_.reshape((-1,256))\n",
    "z_reshape_rot2 = np.transpose(z_reshape2)\n",
    "add_zeros = np.zeros((1,2400))\n",
    "z_nonmat = np.concatenate((z_reshape_rot2, add_zeros))\n",
    "print(z_nonmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate((z_mat, z_nonmat),axis=1)  #training data\n",
    "\n",
    "scipy.io.savemat('result_FRGC/train_new_ae.mat', mdict={\"X_tr\": train})\n",
    "\n",
    "train_with_binary = np.save('result_FRGC/train_bin_ae.npy', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing genuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_test = []\n",
    "zgen_test_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader_gen):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = VAE_net._encode(data)\n",
    "        decod = VAE_net._decode(z_encoded)\n",
    "\n",
    "        recons_images_genuine_test.append(decod[0].cpu().numpy())\n",
    "        zgen_test_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_test = np.array(recons_images_genuine_test)\n",
    "zgen_test_ = np.array(zgen_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_reshape1_test = zgen_test_.reshape((-1,256))\n",
    "z_reshape_rot1_test = np.transpose(z_reshape1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_test = []\n",
    "zim_test_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader_im):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = VAE_net._encode(data)\n",
    "        decod = VAE_net._decode(z_encoded)\n",
    "\n",
    "        recons_images_impostor_test.append(decod[0].cpu().numpy())\n",
    "        zim_test_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_test = np.array(recons_images_impostor_test)\n",
    "zim_test_ = np.array(zim_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_reshape2_test = zim_test_.reshape((-1,256))\n",
    "z_reshape_rot2_test = np.transpose(z_reshape2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "test_gen_pair = np.concatenate((z_reshape_rot1_test, z_reshape_rot2_test), axis=1)\n",
    "\n",
    "scipy.io.savemat('result_FRGC/test_gen_pair_ae.mat', mdict={\"X\": test_gen_pair})\n",
    "\n",
    "np.save('result_FRGC/test_gen_pair_ae.npy', test_gen_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('result_FRGC/train_bin_vae.npy')\n",
    "test = np.load('result_FRGC/test_gen_pair_vae.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7278795153177869\n",
      "(array([7]),)\n"
     ]
    }
   ],
   "source": [
    "#Finding the best Ndc value\n",
    "find = []\n",
    "\n",
    "for i in range(128):\n",
    "    M_global_hat, B_psinv, stdB_hat = train_LLR(train, Npc=128, Ndc=i)\n",
    "    LLR = LLR_computation(test, M_global_hat, B_psinv, stdB_hat)\n",
    "    \n",
    "    roc_auc = sklearn.metrics.roc_auc_score(gt, LLR[0])\n",
    "\n",
    "    find.append(roc_auc)\n",
    "\n",
    "find = np.array(find)\n",
    "print(np.max(find))\n",
    "\n",
    "print(np.where(find == np.max(find)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_global_hat, B_psinv, stdB_hat = train_LLR(train, Npc=128, Ndc=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240,)\n"
     ]
    }
   ],
   "source": [
    "LLR = LLR_computation(test, M_global_hat, B_psinv, stdB_hat)\n",
    "#print(LLR)\n",
    "print(LLR[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7279\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = sklearn.metrics.roc_auc_score(gt, LLR[0])\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(gt, LLR[0])\n",
    "print ('ROC-AUC: %.04f' % roc_auc)\n",
    "# Plot and save ROC curve\n",
    "fig = plt.figure()\n",
    "plt.title('ROC - VAE z=128')\n",
    "plt.plot(fpr, tpr, lw=2, label='ROC (auc = %0.4f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
