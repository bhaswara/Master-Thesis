{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import cv2 \n",
    "import random\n",
    "from scipy.linalg import sqrtm\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "import collections\n",
    "import PIL\n",
    "import tqdm\n",
    "\n",
    "from LLR_classifier import *\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True\n",
    "use_cuda = USE_CUDA and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "batch_size = 100\n",
    "z_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super(View, self).__init__()\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor.view(self.size)\n",
    "\n",
    "def kaiming_init(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        init.kaiming_normal(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "        m.weight.data.fill_(1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "    \n",
    "class WAE(nn.Module):\n",
    "    def __init__(self, z_dim=10, nc=3):\n",
    "        super(WAE, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.nc = nc\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(nc, 128, 4, 2, 1, bias=False),              \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),             \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),             \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),            \n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(True),\n",
    "            View((-1, 1024*4*4)),                                 \n",
    "            nn.Linear(1024*4*4, z_dim)                            \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, 1024*8*8),                           \n",
    "            View((-1, 1024, 8, 8)),                               \n",
    "            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False),   \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),    \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),    \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, nc, 1),                       \n",
    "        )\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self._encode(x)\n",
    "        x_recon = self._decode(z)\n",
    "\n",
    "        return x_recon, z\n",
    "\n",
    "    def _encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def _decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "class Adversary(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Adversary, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, 512),                                \n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),                                  \n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),                                  \n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),                                  \n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1),                                    \n",
    "        )\n",
    "        self.weight_init()\n",
    "\n",
    "    def weight_init(self):\n",
    "        for block in self._modules:\n",
    "            for m in self._modules[block]:\n",
    "                kaiming_init(m)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/irfandw/anaconda3/envs/env/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "WAE_net = WAE(z_dim=128, nc=3)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    WAE_net = WAE_net.cuda()\n",
    "\n",
    "WAE_net.load_state_dict(torch.load('saved_model_x2/WAE.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train image directory\n",
    "train_path = '/home/irfandw/Works/dataset/data_aligned_resize/copy1/Training/Subjects/'\n",
    "\n",
    "#Test image directory\n",
    "test_path = '/home/irfandw/Works/dataset/data_aligned_resize/FRGC/Testing/Subjects/'\n",
    "\n",
    "\n",
    "#Pair train of FRGC directory\n",
    "pairs_path1 = 'pairs_new/train/shufflepairs_genuine.txt'\n",
    "pairs_path2 = 'pairs_new/train/shufflepairs_train_impostor_new.txt'\n",
    "\n",
    "#Pair test of FRGC directory\n",
    "pairs_test1 = 'pairs_frgc/shufflepairs_FRGC_test_genuine.txt'\n",
    "pairs_test2 = 'pairs_frgc/shufflepairs_FRGC_test_impostor.txt'\n",
    "pairs_path3 = 'pairs_frgc/pairs_frgc.txt'\n",
    "\n",
    "\n",
    "file_ext = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pairs(pairs_filename, lfw_flag=True):\n",
    "    pairs = []\n",
    "    with open(pairs_filename, 'r') as f:\n",
    "        if lfw_flag:\n",
    "            for line in f.readlines()[1:]:\n",
    "                pair = line.strip().split()\n",
    "                pairs.append(pair)\n",
    "        else:\n",
    "            for line in f.readlines():\n",
    "                pair = line.strip().split()\n",
    "                pairs.append(pair)      \n",
    "    return np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training pairs\n",
    "pairs1 = read_pairs(pairs_path1, lfw_flag=False)\n",
    "pairs2 = read_pairs(pairs_path2, lfw_flag=False)\n",
    "\n",
    "#Load testing pairs\n",
    "pairtest1 = read_pairs(pairs_test1, lfw_flag=False)\n",
    "pairtest2 = read_pairs(pairs_test2, lfw_flag=False)\n",
    "pairsx = read_pairs(pairs_path3, lfw_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of path for training and testing pairs\n",
    "def get_paths(directory, pairs, file_ext):\n",
    "    nrof_skipped_pairs = 0\n",
    "    path_list = []\n",
    "    issame_list = []\n",
    "    for pair in pairs:\n",
    "        if len(pair) == 3:\n",
    "            path0 = os.path.join(directory, pair[0], pair[1])\n",
    "            path1 = os.path.join(directory, pair[0], pair[2])\n",
    "            issame = True\n",
    "        elif len(pair) == 4:\n",
    "            path0 = os.path.join(directory, pair[0], pair[1])\n",
    "            path1 = os.path.join(directory, pair[2], pair[3])\n",
    "            issame = False\n",
    "        if os.path.exists(path0) and os.path.exists(path1):    # Only add the pair if both paths exist\n",
    "            path_list += (path0,path1)\n",
    "            issame_list.append(issame)\n",
    "        else:\n",
    "            nrof_skipped_pairs += 1\n",
    "    if nrof_skipped_pairs>0:\n",
    "        print('Skipped %d image pairs' % nrof_skipped_pairs)\n",
    "    \n",
    "    return path_list, issame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training and testing\n",
    "path_list1, issame_list1 = get_paths(train_path, pairs1, file_ext)\n",
    "path_list2, issame_list2 = get_paths(train_path, pairs2, file_ext)\n",
    "\n",
    "path_list_test1, issame_list_test1 = get_paths(test_path, pairtest1, file_ext)\n",
    "path_list_test2, issame_list_test2 = get_paths(test_path, pairtest2, file_ext)\n",
    "path_list3, issame_list3 = get_paths(test_path, pairsx, file_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ground truth\n",
    "gt = np.asarray(issame_list3)\n",
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, path_list, issame_list, transforms, split = 'test'):\n",
    "        \n",
    "        self.files = collections.defaultdict(list)\n",
    "        self.split = split\n",
    "        self.files[split] =  path_list\n",
    "        self.pair_label = issame_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files[self.split])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_file = self.files[self.split][index]\n",
    "        img = PIL.Image.open(img_file)\n",
    "        if DEBUG:\n",
    "            print (img_file)\n",
    "        im_out = self.transforms(img)\n",
    "        return im_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training dataset\n",
    "train_loader_gen = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list1, issame_list1, test_transform), \n",
    "                        batch_size=1, shuffle=False )\n",
    "\n",
    "train_loader_im = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list2, issame_list2, test_transform), \n",
    "                        batch_size=1, shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load testing dataset\n",
    "test_loader_gen = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list_test1, issame_list_test1, test_transform), \n",
    "                        batch_size=1, shuffle=False )\n",
    "\n",
    "test_loader_im = torch.utils.data.DataLoader(\n",
    "                        LoadDataset(\n",
    "                        path_list_test2, issame_list_test2, test_transform), \n",
    "                        batch_size=1, shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace)\n",
       "    (9): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace)\n",
       "    (12): View()\n",
       "    (13): Linear(in_features=16384, out_features=128, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=65536, bias=True)\n",
       "    (1): View()\n",
       "    (2): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ReLU(inplace)\n",
       "    (8): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace)\n",
       "    (11): ConvTranspose2d(128, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WAE_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Z_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images = []\n",
    "zgen_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(train_loader_gen):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = WAE_net._encode(data)\n",
    "        decod = WAE_net._decode(z_encoded)\n",
    "\n",
    "        recons_images.append(decod[0].cpu().numpy())\n",
    "        zgen_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_train = np.array(recons_images)\n",
    "zgen_ = np.array(zgen_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 2400)\n"
     ]
    }
   ],
   "source": [
    "z_reshape1 = zgen_.reshape((-1,256))\n",
    "z_reshape_rot1 = np.transpose(z_reshape1)\n",
    "add_ones = np.ones((1,2400))\n",
    "z_mat = np.concatenate((z_reshape_rot1, add_ones))\n",
    "print(z_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z_nonmated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_train = []\n",
    "zim_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(train_loader_im):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = WAE_net._encode(data)\n",
    "        decod = WAE_net._decode(z_encoded)\n",
    "\n",
    "        recons_images_impostor_train.append(decod[0].cpu().numpy())\n",
    "        zim_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_train = np.array(recons_images_impostor_train)\n",
    "zim_ = np.array(zim_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 2400)\n"
     ]
    }
   ],
   "source": [
    "z_reshape2 = zim_.reshape((-1,256))\n",
    "z_reshape_rot2 = np.transpose(z_reshape2)\n",
    "add_zeros = np.zeros((1,2400))\n",
    "z_nonmat = np.concatenate((z_reshape_rot2, add_zeros))\n",
    "print(z_nonmat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate((z_mat, z_nonmat),axis=1)  #training data\n",
    "\n",
    "scipy.io.savemat('result_FRGC/train_new_wae.mat', mdict={\"X_tr\": train})\n",
    "\n",
    "train_with_binary = np.save('result_FRGC/train_bin_wae.npy', train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing genuine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_test = []\n",
    "zgen_test_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader_gen):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = WAE_net._encode(data)\n",
    "        decod = WAE_net._decode(z_encoded)\n",
    "\n",
    "        recons_images_genuine_test.append(decod[0].cpu().numpy())\n",
    "        zgen_test_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_genuine_test = np.array(recons_images_genuine_test)\n",
    "zgen_test_ = np.array(zgen_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_reshape1_test = zgen_test_.reshape((-1,256))\n",
    "z_reshape_rot1_test = np.transpose(z_reshape1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Impostor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_test = []\n",
    "zim_test_ = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in enumerate(test_loader_im):\n",
    "        #datax,_ = data\n",
    "        data = data.to(device)\n",
    "\n",
    "        z_encoded = WAE_net._encode(data)\n",
    "        decod = WAE_net._decode(z_encoded)\n",
    "\n",
    "        recons_images_impostor_test.append(decod[0].cpu().numpy())\n",
    "        zim_test_.append(z_encoded[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons_images_impostor_test = np.array(recons_images_impostor_test)\n",
    "zim_test_ = np.array(zim_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_reshape2_test = zim_test_.reshape((-1,256))\n",
    "z_reshape_rot2_test = np.transpose(z_reshape2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "test_gen_pair = np.concatenate((z_reshape_rot1_test, z_reshape_rot2_test), axis=1)\n",
    "\n",
    "scipy.io.savemat('result_FRGC/test_gen_pair_wae.mat', mdict={\"X\": test_gen_pair})\n",
    "\n",
    "np.save('result_FRGC/test_gen_pair_wae.npy', test_gen_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('result_FRGC/train_bin_wae.npy')\n",
    "test = np.load('result_FRGC/test_gen_pair_wae.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305894680688919\n",
      "(array([125]),)\n"
     ]
    }
   ],
   "source": [
    "#Finding the best Ndc value\n",
    "find = []\n",
    "\n",
    "for i in range(128):\n",
    "    M_global_hat, B_psinv, stdB_hat = train_LLR(train, Npc=128, Ndc=i)\n",
    "    LLR = LLR_computation(test, M_global_hat, B_psinv, stdB_hat)\n",
    "    \n",
    "    roc_auc = sklearn.metrics.roc_auc_score(gt, LLR[0])\n",
    "\n",
    "    find.append(roc_auc)\n",
    "\n",
    "find = np.array(find)\n",
    "print(np.max(find))\n",
    "print(np.where(find == np.max(find)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_global_hat, B_psinv, stdB_hat = train_LLR(train, Npc=128, Ndc=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240,)\n"
     ]
    }
   ],
   "source": [
    "LLR = LLR_computation(test, M_global_hat, B_psinv, stdB_hat)\n",
    "#print(LLR)\n",
    "print(LLR[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8306\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = sklearn.metrics.roc_auc_score(gt, LLR[0])\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(gt, LLR[0])\n",
    "print ('ROC-AUC: %.04f' % roc_auc)\n",
    "# Plot and save ROC curve\n",
    "fig = plt.figure()\n",
    "plt.title('ROC - WAE z=128')\n",
    "plt.plot(fpr, tpr, lw=2, label='ROC (auc = %0.4f)' % roc_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
